#----coding:utf-8-----import numpy as npimport xgboost as xgbimport pandas as pdfrom sklearn.cross_validation import train_test_splitfrom sklearn.metrics import mean_squared_error, r2_scoredata = pd.DataFrame(pd.read_csv('IO/one_fill.csv'))train_ , test_ = train_test_split(data, test_size=0.3, random_state=20)train_xy, val = train_test_split(train_, test_size=0.2, random_state=20)train_y = train_xy['A']train_x = train_xy.drop(['A'], axis=1)val_y = val['A']val_x = val.drop(['A'], axis=1)test_y = test_['A']test_x = xgb.DMatrix(test_.drop(['A'], axis=1))xgb_train = xgb.DMatrix(train_x, train_y)xgb_val = xgb.DMatrix(val_x, val_y)parameters = {    'booster' : 'gbtree',    'objective' : 'reg:linear',    'eval_metric': 'rmse',    'gamma': 0.1,    'max_depth': 7,    'subsample':0.8,    'colsample_bytree': 0.7,    'eta': 0.06}num_rounds = 150watchlist = [(xgb_train,'train'),(xgb_val, 'val')]model = xgb.train(parameters, xgb_train, num_rounds, watchlist, early_stopping_rounds=100)pred = model.predict(test_x)# print(pred )print("Root Mean Squared Error: %.10f"  % np.sqrt(mean_squared_error(test_y, pred)))print('R2 score: %.10f' % r2_score(test_y, pred))